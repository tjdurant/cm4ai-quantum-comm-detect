{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/wschulz/.kaggle/kaggle.json'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "from sklearn.metrics import adjusted_mutual_info_score, adjusted_rand_score\n",
    "\n",
    "import algorithm.kcomm.graph_kClusterAlgorithm_functions_optimized as QCD\n",
    "import algorithm.kcomm.graphFileUtility_functions as GFU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/wschulz/.kaggle/kaggle.json'\n"
     ]
    }
   ],
   "source": [
    "# Initialize and authenticate the Kaggle API\n",
    "api = KaggleApi()\n",
    "api.authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data\"\n",
    "competition = 'cm4ai-community-detection-benchmark'\n",
    "data_path = os.path.join(data_dir, competition)\n",
    "os.makedirs(data_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"../output\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download all files from a competition (e.g., Titanic)\n",
    "competition = 'cm4ai-community-detection-benchmark'\n",
    "api.competition_download_files(competition, path=data_dir, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all files from the zip to the specified directory\n",
    "zip_file_path = data_path + \".zip\"\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_dict = {\n",
    "    \"output_dir\" : output_dir\n",
    "}\n",
    "run_profile=\"defaults\"\n",
    "beta0 = 5\n",
    "gamma0 = -250\n",
    "threshold = 0.2\n",
    "qsize = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_label = \"graph1\"\n",
    "input_graph = f\"../data/cm4ai-community-detection-benchmark/{run_label}\"\n",
    "\n",
    "G = nx.read_edgelist(f\"{input_graph}.edgelist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Adjacency matrix:\n",
      " [[0 1 1 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 1]]\n",
      "\n",
      "Quantum Community Detection: Up to 20 communities\n",
      "Graph has 500 nodes and 981 edges\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5261/2126749976.py:1: FutureWarning: adjacency_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "  A = nx.adjacency_matrix(G)\n"
     ]
    }
   ],
   "source": [
    "A = nx.adjacency_matrix(G)\n",
    "print ('\\nAdjacency matrix:\\n', A.todense())\n",
    "\n",
    "# num_parts = len(np.unique(gt_arr))\n",
    "num_parts = 20                              # TODO: What should we put for num_parts?\n",
    "num_blocks = num_parts \n",
    "num_nodes = nx.number_of_nodes(G)\n",
    "num_edges = nx.number_of_edges(G)\n",
    "print (f\"\\nQuantum Community Detection: Up to {num_parts} communities\")\n",
    "print (f\"Graph has {num_nodes} nodes and {num_edges} edges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta, gamma, GAMMA  = QCD.set_penalty_constant(num_nodes, num_blocks, beta0, gamma0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Dim =  500\n",
      "\n",
      " Computing modularity matrix ...\n",
      "\n",
      "Modularity matrix: \n",
      " [[-8.355e-03  9.896e-01  9.958e-01 ... -4.178e-03 -2.089e-03 -2.089e-03]\n",
      " [ 9.896e-01 -1.305e-02 -5.222e-03 ... -5.222e-03 -2.611e-03 -2.611e-03]\n",
      " [ 9.958e-01 -5.222e-03 -2.089e-03 ... -2.089e-03 -1.044e-03 -1.044e-03]\n",
      " ...\n",
      " [-4.178e-03 -5.222e-03 -2.089e-03 ... -2.089e-03 -1.044e-03 -1.044e-03]\n",
      " [-2.089e-03 -2.611e-03 -1.044e-03 ... -1.044e-03  9.995e-01 -5.222e-04]\n",
      " [-2.089e-03 -2.611e-03 -1.044e-03 ... -1.044e-03 -5.222e-04  9.995e-01]]\n",
      "min value =  -0.31018276762402086\n",
      "max value =  0.9994778067885117\n",
      "threshold =  0.2\n"
     ]
    }
   ],
   "source": [
    "mtotal, modularity = QCD.build_mod(A, threshold, num_edges)\n",
    "print (\"\\nModularity matrix: \\n\", modularity)\n",
    "\n",
    "print (\"min value = \", modularity.min())\n",
    "print (\"max value = \", modularity.max())\n",
    "\n",
    "print (\"threshold = \", threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wschulz/miniconda3/envs/cm4ai-quantum/lib/python3.9/site-packages/numba/core/lowering.py:112: NumbaDebugInfoWarning: Could not find source for function: <function __numba_parfor_gufunc_0x79a5bdef5d30 at 0x79a5bdef4e50>. Debug line information may be inaccurate.\n",
      "  warnings.warn(NumbaDebugInfoWarning(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix size: 10000\n"
     ]
    }
   ],
   "source": [
    "Q = QCD.makeQubo(modularity, beta, gamma, GAMMA, num_nodes, num_parts, num_blocks, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_clusters': 20,\n",
       " 'nodes': 500,\n",
       " 'edges': 981,\n",
       " 'size': 10000,\n",
       " 'subqubo_size': 64}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = {}\n",
    "result['num_clusters'] = num_parts \n",
    "result['nodes'] = num_nodes\n",
    "result['edges'] = num_edges\n",
    "result['size'] = num_nodes * num_parts \n",
    "result['subqubo_size'] = qsize\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Q size =  10000\n",
      "   0  1  2  3  4  5  6  7  8  9 10 11 12 13 ... 9999         energy num_oc. ...\n",
      "0  0  0  0  0  0  1  1  1  1  1  0  0  0  0 ...    0 -133835.101828       2 ...\n",
      "3  1  0  1  1  1  1  1  1  1  1  0  0  0  0 ...    0 -133812.704961       1 ...\n",
      "2  1  1  1  1  1  1  1  1  1  1  1  1  1  1 ...    0 -133762.313316       1 ...\n",
      "1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 ...    0 -133748.558747       1 ...\n",
      "4  1  1  1  1  1  1  1  1  1  1  1  1  1  1 ...    0 -126403.603133       1 ...\n",
      "['BINARY', 5 rows, 6 samples, 10000 variables]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'num_clusters': 20,\n",
       " 'nodes': 500,\n",
       " 'edges': 981,\n",
       " 'size': 10000,\n",
       " 'subqubo_size': 64,\n",
       " 'wall_clock_time_seconds': 34.783062,\n",
       " 'num_qpu_accesses': 5,\n",
       " 'total_qpu_time': 159135.8,\n",
       " 'energy': -133835.10182767647,\n",
       " 'num_occ': 2,\n",
       " 'num_diff_solns': 5,\n",
       " 'total_solns': 6}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run k-clustering with Hybrid/D-Wave using ocean\n",
    "ss = QCD.clusterHybrid(Q, num_parts, qsize, run_label, run_profile, result)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "num non-zeros =  500\n",
      "\n",
      "last part size 0 -25.0\n",
      "part 0 has 431 nodes\n",
      "part 1 has 0 nodes\n",
      "part 2 has 0 nodes\n",
      "part 3 has 0 nodes\n",
      "part 4 has 0 nodes\n",
      "part 5 has 0 nodes\n",
      "part 6 has 0 nodes\n",
      "part 7 has 0 nodes\n",
      "part 8 has 0 nodes\n",
      "part 9 has 0 nodes\n",
      "part 10 has 0 nodes\n",
      "part 11 has 0 nodes\n",
      "part 12 has 2 nodes\n",
      "part 13 has 0 nodes\n",
      "part 14 has 0 nodes\n",
      "part 15 has 66 nodes\n",
      "part 16 has 0 nodes\n",
      "part 17 has 0 nodes\n",
      "part 18 has 1 nodes\n",
      "part 19 has 0 nodes\n"
     ]
    }
   ],
   "source": [
    "# Process solution\n",
    "part_number = QCD.process_solution(ss, G, num_blocks, num_nodes, num_parts, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Dim =  500\n"
     ]
    }
   ],
   "source": [
    "mmetric = QCD.calcModularityMetric(mtotal, modularity, part_number)\n",
    "result['modularity_metric'] = mmetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw graph clusters and save .png\n",
    "GFU.showClusters(part_number, G, args_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "# write comms file \n",
    "GFU.write_partFile(\n",
    "    part_num=part_number, \n",
    "    Dim=num_nodes, \n",
    "    nparts=num_parts, \n",
    "    args_dict=args_dict\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15, 15, 15, 15, 15, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = [\"node_id\", \"comm_id\"]\n",
    "communities = []\n",
    "\n",
    "pred_arr=[]\n",
    "\n",
    "comm_file_path = os.path.join(args_dict['output_dir'], f\"comm{num_parts}.txt\")\n",
    "with open(comm_file_path) as comm_file:\n",
    "    i = 0\n",
    "    for line in comm_file:\n",
    "        i += 1\n",
    "        if i == 1:\n",
    "            continue\n",
    "        fields = line.strip().split(\"  \")\n",
    "        communities.append(fields)\n",
    "        pred_arr.append(fields[1])\n",
    "\n",
    "pred_arr = [int(x) for x in pred_arr]\n",
    "pred_arr[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_file_path = os.path.join(args_dict['output_dir'], 'submission.csv')\n",
    "with open(comm_file_path, 'r') as infile, open(submission_file_path, 'w') as submission_file:\n",
    "    # Skip the first line\n",
    "    next(infile)\n",
    "    submission_file.write(\"id,prediction\" + \"\\n\")\n",
    "    for line in infile:\n",
    "        # Strip the line and split by whitespace\n",
    "        fields = line.strip().split()\n",
    "        # Join fields with commas\n",
    "        csv_line = \",\".join(fields)\n",
    "        submission_file.write(csv_line + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2.90k/2.90k [00:00<00:00, 4.61kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission complete!\n"
     ]
    }
   ],
   "source": [
    "# Submit the file\n",
    "api.competition_submit(file_name=submission_file_path, competition=competition, message=\"Submission\")\n",
    "\n",
    "print(\"Submission complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cm4ai-quantum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
