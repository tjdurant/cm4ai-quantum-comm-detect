{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "from sklearn.metrics import adjusted_mutual_info_score, adjusted_rand_score\n",
    "\n",
    "import algorithm.kcomm.graph_kClusterAlgorithm_functions as QCD\n",
    "import algorithm.kcomm.graphFileUtility_functions as GFU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and authenticate the Kaggle API\n",
    "api = KaggleApi()\n",
    "api.authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data\"\n",
    "competition = 'cm4ai-community-detection-benchmark'\n",
    "data_path = os.path.join(data_dir, competition)\n",
    "os.makedirs(data_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"../output\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download all files from a competition (e.g., Titanic)\n",
    "competition = 'cm4ai-community-detection-benchmark'\n",
    "api.competition_download_files(competition, path=data_dir, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all files from the zip to the specified directory\n",
    "zip_file_path = data_path + \".zip\"\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_dict = {\n",
    "    \"output_dir\" : output_dir\n",
    "}\n",
    "run_profile=\"defaults\"\n",
    "beta0 = 5\n",
    "gamma0 = -250\n",
    "threshold = 0.2\n",
    "qsize = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_label = \"graph1\"\n",
    "input_graph = f\"../data/cm4ai-community-detection-benchmark/{run_label}\"\n",
    "\n",
    "G = nx.read_edgelist(f\"{input_graph}.edgelist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = nx.adjacency_matrix(G)\n",
    "print ('\\nAdjacency matrix:\\n', A.todense())\n",
    "\n",
    "# num_parts = len(np.unique(gt_arr))\n",
    "num_parts = 32                              # TODO: What should we put for num_parts?\n",
    "num_blocks = num_parts \n",
    "num_nodes = nx.number_of_nodes(G)\n",
    "num_edges = nx.number_of_edges(G)\n",
    "print (f\"\\nQuantum Community Detection: Up to {num_parts} communities\")\n",
    "print (f\"Graph has {num_nodes} nodes and {num_edges} edges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta, gamma, GAMMA  = QCD.set_penalty_constant(num_nodes, num_blocks, beta0, gamma0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtotal, modularity = QCD.build_mod(A, threshold, num_edges)\n",
    "print (\"\\nModularity matrix: \\n\", modularity)\n",
    "\n",
    "print (\"min value = \", modularity.min())\n",
    "print (\"max value = \", modularity.max())\n",
    "\n",
    "print (\"threshold = \", threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = QCD.makeQubo(G, modularity, beta, gamma, GAMMA, num_nodes, num_parts, num_blocks, threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {}\n",
    "result['num_clusters'] = num_parts \n",
    "result['nodes'] = num_nodes\n",
    "result['edges'] = num_edges\n",
    "result['size'] = num_nodes * num_parts \n",
    "result['subqubo_size'] = qsize\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run k-clustering with Hybrid/D-Wave using ocean\n",
    "ss = QCD.clusterHybrid(Q, num_parts, qsize, run_label, run_profile, result)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process solution\n",
    "part_number = QCD.process_solution(ss, G, num_blocks, num_nodes, num_parts, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmetric = QCD.calcModularityMetric(mtotal, modularity, part_number)\n",
    "result['modularity_metric'] = mmetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw graph clusters and save .png\n",
    "GFU.showClusters(part_number, G, args_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write comms file \n",
    "GFU.write_partFile(\n",
    "    part_num=part_number, \n",
    "    Dim=num_nodes, \n",
    "    nparts=num_parts, \n",
    "    args_dict=args_dict\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"node_id\", \"comm_id\"]\n",
    "communities = []\n",
    "\n",
    "pred_arr=[]\n",
    "\n",
    "comm_file_path = os.path.join(args_dict['output_dir'], f\"comm{num_parts}.txt\")\n",
    "with open(comm_file_path) as comm_file:\n",
    "    i = 0\n",
    "    for line in comm_file:\n",
    "        i += 1\n",
    "        if i == 1:\n",
    "            continue\n",
    "        fields = line.strip().split(\"  \")\n",
    "        communities.append(fields)\n",
    "        pred_arr.append(fields[1])\n",
    "\n",
    "pred_arr = [int(x) for x in pred_arr]\n",
    "pred_arr[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_file_path = os.path.join(args_dict['output_dir'], 'submission.csv')\n",
    "with open(comm_file_path, 'r') as infile, open(submission_file_path, 'w') as submission_file:\n",
    "    # Skip the first line\n",
    "    next(infile)\n",
    "\n",
    "    for line in infile:\n",
    "        # Strip the line and split by whitespace\n",
    "        fields = line.strip().split()\n",
    "        # Join fields with commas\n",
    "        csv_line = \",\".join(fields)\n",
    "        submission_file.write(csv_line + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit the file\n",
    "api.competition_submit(file_name=submission_file_path, competition=competition)\n",
    "\n",
    "print(\"Submission complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cm4ai-quantum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
