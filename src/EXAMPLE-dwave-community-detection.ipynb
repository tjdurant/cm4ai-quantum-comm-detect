{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from community import community_louvain\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "from sklearn.metrics import adjusted_mutual_info_score, adjusted_rand_score\n",
    "\n",
    "import algorithm.kcomm.graph_kClusterAlgorithm_functions as QCD\n",
    "import algorithm.kcomm.graphFileUtility_functions as GFU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and authenticate the Kaggle API\n",
    "api = KaggleApi()\n",
    "api.authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data\"\n",
    "competition = 'cm4ai-community-detection-benchmark'\n",
    "data_path = os.path.join(data_dir, competition)\n",
    "os.makedirs(data_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"../output\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download all files from a competition (e.g., Titanic)\n",
    "competition = 'cm4ai-community-detection-benchmark'\n",
    "api.competition_download_files(competition, path=data_dir, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all files from the zip to the specified directory\n",
    "zip_file_path = data_path + \".zip\"\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_dict = {\n",
    "    \"benchmark_gen\":\"football\",\n",
    "    \"output_dir\" : output_dir\n",
    "}\n",
    "\n",
    "beta0 = 5\n",
    "gamma0 = -250\n",
    "threshold = 0.2\n",
    "qsize = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_profile=\"defaults\"\n",
    "\n",
    "if args_dict[\"benchmark_gen\"] == 'karate':\n",
    "\n",
    "    print(f\"Using benchmark graph generated by: nx-karate\")  \n",
    "    \n",
    "    run_label = \"zacharys-karate-club\"\n",
    "    input_graph = \"zacharys-karate-club\"\n",
    "    \n",
    "    G = nx.karate_club_graph() \n",
    "\n",
    "    gt_arr = []\n",
    "    gt_arr = [G.nodes[v]['club'] for v in G.nodes()]\n",
    "    gt_arr = [0 if x == 'Mr. Hi' else 1 for x in gt_arr]        # Convert to binary labels\n",
    "\n",
    "\n",
    "elif args_dict[\"benchmark_gen\"] == 'networkx':\n",
    "    \n",
    "    print(f\"Using benchmark graph generated by: networkx\")    \n",
    "\n",
    "    run_label = \"LFR_rs11_N1000_ad5_mc20_mu0.1\"\n",
    "    input_graph = f\"../data/cm4ai-community-detection-benchmark/{run_label}\"\n",
    "\n",
    "    G = nx.read_edgelist(f\"{input_graph}.edgelist\")\n",
    "\n",
    "    df = pd.read_csv(f\"{input_graph}_communities.csv\")\n",
    "    gt_dict = df.set_index('id')['solution'].to_dict()\n",
    "\n",
    "    sorted_by_keys = dict(sorted(gt_dict.items()))\n",
    "    gt_arr = []\n",
    "    for k,v in sorted_by_keys.items():\n",
    "        gt_arr.append(v)\n",
    "\n",
    "elif args_dict[\"benchmark_gen\"] == 'dynbench':\n",
    "\n",
    "    print(f\"Using benchmark graph generated by: Dynbench\")    \n",
    "    \n",
    "    # n = Number of nodes per community\n",
    "    # q = Number of communities\n",
    "    run_label = \"stdmerge-n32-q8-pout01.t00100\"\n",
    "    input_graph = f\"../data/cm4ai-community-detection-benchmark/{run_label}.graph\"\n",
    "    ground_truth_path = f\"../data/scm4ai-community-detection-benchmark/{run_label}.comms\"\n",
    "\n",
    "    edgelist = pd.read_csv(input_graph, sep=' ', names=[\"source\",\"target\"])\n",
    "    G = nx.from_pandas_edgelist(edgelist)\n",
    "    for edge in G.edges():\n",
    "        G[edge[0]][edge[1]]['weight'] = 1\n",
    "\n",
    "    gt_arr=[]\n",
    "    with open(ground_truth_path) as ground_truth_file:\n",
    "        for line in ground_truth_file:\n",
    "            if line.startswith(\"#\"):\n",
    "                continue\n",
    "            fields = line.strip().split(\" \")\n",
    "            gt_arr.append(fields[1])\n",
    "elif args_dict[\"benchmark_gen\"] == 'football':\n",
    "\n",
    "    print(f\"Using benchmark graph generated by: Football\")    \n",
    "    \n",
    "    run_label = \"football\"\n",
    "    input_graph = f\"../data/cm4ai-community-detection-benchmark/football_adjacency_matrix.csv\"\n",
    "    ground_truth_path = f\"../data/cm4ai-community-detection-benchmark/football_labels.csv\"\n",
    "    adj_matrix = np.loadtxt(input_graph, delimiter=\",\", skiprows=1)\n",
    "    print (adj_matrix.shape)\n",
    "    # Create a graph from the adjacency matrix\n",
    "    G = nx.from_numpy_matrix(adj_matrix)\n",
    "\n",
    "    gt_arr=[]\n",
    "    with open(ground_truth_path) as ground_truth_file:\n",
    "        reader = csv.reader(ground_truth_file)\n",
    "        next(reader)  # Skip the header\n",
    "        for row in reader:\n",
    "            gt_arr.append(int(row[1]))  # Add the second field (index 1) to the array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(\n",
    "    G, \n",
    "    node_size=50,\n",
    "    width=0.5,\n",
    "    node_color=\"grey\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = nx.adjacency_matrix(G)\n",
    "print ('\\nAdjacency matrix:\\n', A.todense())\n",
    "\n",
    "num_parts = len(np.unique(gt_arr))\n",
    "num_blocks = num_parts \n",
    "num_nodes = nx.number_of_nodes(G)\n",
    "num_edges = nx.number_of_edges(G)\n",
    "print (f\"\\nQuantum Community Detection: Up to {num_parts} communities\")\n",
    "print (f\"Graph has {num_nodes} nodes and {num_edges} edges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta, gamma, GAMMA  = QCD.set_penalty_constant(num_nodes, num_blocks, beta0, gamma0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtotal, modularity = QCD.build_mod(A, threshold, num_edges)\n",
    "print (\"\\nModularity matrix: \\n\", modularity)\n",
    "\n",
    "print (\"min value = \", modularity.min())\n",
    "print (\"max value = \", modularity.max())\n",
    "\n",
    "print (\"threshold = \", threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = QCD.makeQubo(G, modularity, beta, gamma, GAMMA, num_nodes, num_parts, num_blocks, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {}\n",
    "result['num_clusters'] = num_parts \n",
    "result['nodes'] = num_nodes\n",
    "result['edges'] = num_edges\n",
    "result['size'] = num_nodes * num_parts \n",
    "result['subqubo_size'] = qsize\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run k-clustering with Hybrid/D-Wave using ocean\n",
    "ss = QCD.clusterHybrid(Q, num_parts, qsize, run_label, run_profile, result)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process solution\n",
    "part_number = QCD.process_solution(ss, G, num_blocks, num_nodes, num_parts, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmetric = QCD.calcModularityMetric(mtotal, modularity, part_number)\n",
    "result['modularity_metric'] = mmetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw graph clusters and save .png\n",
    "GFU.showClusters(part_number, G, args_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write comms file \n",
    "GFU.write_partFile(\n",
    "    part_num=part_number, \n",
    "    Dim=num_nodes, \n",
    "    nparts=num_parts, \n",
    "    args_dict=args_dict\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"node_id\", \"comm_id\"]\n",
    "communities = []\n",
    "\n",
    "pred_arr=[]\n",
    "\n",
    "comm_file_path = os.path.join(args_dict['output_dir'], f\"comm{num_parts}.txt\")\n",
    "with open(comm_file_path) as comm_file:\n",
    "    i = 0\n",
    "    for line in comm_file:\n",
    "        i += 1\n",
    "        if i == 1:\n",
    "            continue\n",
    "        fields = line.strip().split(\"  \")\n",
    "        communities.append(fields)\n",
    "        pred_arr.append(fields[1])\n",
    "\n",
    "pred_arr = [int(x) for x in pred_arr]\n",
    "pred_arr[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_arr[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modularity = nx.community.modularity(G, pred_arr)\n",
    "print(f\"Modularity: {result['modularity_metric']}\")\n",
    "result['ari_score'] = adjusted_rand_score(gt_arr, pred_arr)\n",
    "print(f\"ARI: {result['ari_score']}\")\n",
    "result['ami_score'] = adjusted_mutual_info_score(gt_arr,pred_arr)\n",
    "print(f\"AMI: {result['ami_score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Louvain Community Detection ---\n",
    "# Perform Louvain community detection\n",
    "louvain_partition = community_louvain.best_partition(G, resolution=1.5)\n",
    "num_communities_louvain = len(set(louvain_partition.values()))\n",
    "print(\"Number of communities (Louvain):\", num_communities_louvain)\n",
    "\n",
    "# --- Calculate Modularity ---\n",
    "modularity_score = community_louvain.modularity(louvain_partition, G)\n",
    "print(f\"Modularity: {modularity_score}\")\n",
    "\n",
    "louvain_pred_arr = [louvain_partition[node] for node in G.nodes]\n",
    "\n",
    "# --- Calculate ARI and AMI ---\n",
    "ari_score = adjusted_rand_score(gt_arr, louvain_pred_arr)\n",
    "ami_score = adjusted_mutual_info_score(gt_arr, louvain_pred_arr)\n",
    "print(f\"ARI: {ari_score}\")\n",
    "print(f\"AMI: {ami_score}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cm4ai-quantum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
